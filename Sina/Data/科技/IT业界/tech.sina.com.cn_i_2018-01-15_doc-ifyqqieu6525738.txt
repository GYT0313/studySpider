　　新浪科技讯 1月15日消息，在“新时代 新发展”的清华五道口金融EMBA&EE 2018年新年思想汇活动中，清华大学计算机系人交互与媒体集成研究所长、信息科技术国家实验室普适计算研究部主任、全球创新学院 （GIX） 学院院长史元春，进行了题为“智能交互——让机器更懂你”的分享。她认为在普适计算机时代，随着更多的嵌入式设备的出现，如何更加自然地进行人机之间的信息交换具有重要意义。　　史元春指出，在计算机几十年的发展过程中，人机交互也就是人和机器之间的信息交换的技术，我们可以不夸张的说，也是一项引领性的技术。而人工智能和大数据的进步使人机交互成为现实、可用。　　史元春认为，人机交互的目的是为了让机器更懂“你”，让用户更加自如。她还通过“胖手指”、“空中打字”等案例分享了人机交互领域一些前沿的技术突破。　　“智能技术的研究，也就是我们把一些模糊和用户行为习惯识别为具体、准确交互意图的研究，大有可为”，史元春认为，未来有望通过数据采集和建模来捕捉用户的所有姿态和行为，从而生产出真正理解用户的手机，让手机交互行为的感知更加精准和智能。　　史元春表示，人工智能技术的深度应用，能做到从模糊的行为习惯中解读出准确的意图，将为未来人机共生提供可靠的技术基础。（王上）　　　各位下午好，非常荣幸有这个机会和五道口金融学院的老师和学生们交流，我叫史元春。我跟大家的经历不太一样，来自于计算机系。并且我在这个学校和计算机系有30多年了，从学生到老师。简介中谈到我是GIX学院院长。GIX的英文叫Global Innovation Exchange，是清华大学全球创新学员，它也是清华第一个在海外办起来的学院。　　是我们在两年多以前在美国的西雅图和华盛顿大学联合创办，也很欢迎我们更多的五道口金融学院的同学，能够有机会去西雅图，我们清华那样一个特别的学区来学习和交流。　　今天这个演讲的题目是关于我的科研的，科目叫智能交互。这里的交互是指人机交互。我们知道计算机的发展历史只有几十年，不是很长，但是这几十年来它已经和正在为我们的社会发展带来了巨大的变化，在计算机几十年的发展过程中，人机交互也就是人和机器之间的信息交换的技术，我们可以不夸张的说，也是一项引领性的技术。　　从我的这个表上大家应该可以看的出来，随着接口技术的变化，交互模式也发生了变化，计算机从实验室、机房已经走到了我们的办公室、家庭，甚至今天已经都走到了我们的手上，计算机的台数也发生了极大的数量级变化。　　到了今天，我们已经走到了所谓的普适计算的时代，也就是说在我们的工作和生活的很多方面，我们有特殊的手持的设备，像今天的手机，也有更多的嵌入式的系统，像家电设备，还有更多实业以及社会生活场景会有越来越多这样的设备，我们人们会有更多、更频繁的，并且希望与更自然的方式，和这个机器发生着关系。　　也就是说我们可能会与手持的设备、家电的设备、穿戴的设备，机器人和无人车，以更自然的模态，G比如说包括用语音、用语义丰富的手势，甚至是我们日常的行为，在很多的场景中，可以跟机器的系统，计算的系统发生互动，有效的来进行信息访问和信息系统提供给我们的现实服务。这些接口、终端和任务，我都在我们使用过程中，首位的自然，就是需要我们的人不需要那样很精准的表达，是一种模糊的表达和传达的方式。　　但是，在机器端能够给我们精准的理解和服务。　　我们今天的这些交互方式其实还是很规范的，甚至我们都在用的手机，它是一个严谨的结构，一个抽象的概念，我们有一点的学习甚至是记忆的附和，还要有比较准确的表达。　　如果要实现这个人的模糊的表达，到精准的服务之间，需要克服这样一些技术挑战：　　比如我们的交互意图很内在，那么我们获得的数据随机性很大，用故行为的差异性也非常大，应用的场景也是各式各样的。因此，这些问题需要我们在相应的研究中来进行克服，并且人机交互它既包括我们所使用的各种直接的、离用户很近的接口也包括一个交互过程的优化。这里我简单看看接口，它应该保包括从我们人机交互的研究来看，包括计算机用户，输入接口和计算机处理结果，反馈给用户的输出接口。　　从输入来看也就是说我们的人意念产生了一个访问的请求，当然未来如果我们的脑机接口的技术，也就是所谓读脑的技术能够发明的话，那我们就可以直接来获取这个用户的意图。但是，大家可以看到我这个图上画的还是一个虚线，今天还是不太现实的，那么我们的意念还是要通过我们的行为系统传达给机器。　　我们的行为可以是在使用工具，也可以刚才讲到，像自然语言和各种姿态。　　今天在我们的传感技术和识别的技术都有了很多的进步，比如说大家用的这个手机屏，可能留了一个小刘海，今天的大手机屏，那是因为那个上面有10几个传感器，还不能在屏下，只能单独的露出来。我们现在的家庭里面可能已经有智能音箱来帮助我们服务，这个是语音识别技术的进步。甚至于人脸识别已经变成了我们这种身份ID。　　这些技术实际上在几十年前都已经提出来，最近的人工智能和大数据的进步使得成为现实、可用。但是，在交互接口上还有很多需要优化和需要创新的的一些方面。这里我举两个具体的例子：　　大家都有用手机，手机上面我们还是要有我们本输入这样一个基本的任务的。大家在用微信，今天这个场合也有几个人在用，这个时候你通常是在敲，而不是用语音识别，因为需要一个静默的环境。你敲的时候，大家如果用过电脑的话，你会觉得你的速度比用物理键盘慢了一倍，为什么慢？这就是人机交互中很典型的一个问题“胖手指问题”，是因为我们的手指，远比我们点击的对象要模糊的多。也就是对象的精准点击，用我们的fat finger是很难完成的，所以点不准你就慢下来了。　　今天在场有不少人也戴了智能手表，就像这个图一样，我可以给你装一个软件，也会有一个软件全键盘，但有人会用吗？你肯定想着我不会用，因为与我们在手机上进行输入的速度和体验来说，2毫米的小键盘根本不可能用，这是一个典型的fat finger问题。　　可以给大家看一个我们在实验室的研究结果，我们在手机上做了一个全键盘，会看到输入的速度还是可以接受的，实际速度一个实测的结果，跟你在用手机进行输入的速度是一样的，每秒30-40个字左右。这是靠我们对电容图像的智能处理和自然语言模型相结合获得的结果，在一定程度上克服了所谓的胖手指问题。　　用同样的原理，我们还可以提供比如现在手机上很现实的技术，叫防误触。手机的屏幕现在越来越大，有全面屏和曲面屏，同时也会带来一个问题，你握着它的时候会误处。　　同样我们在多特征的图像处理算法上的一些进展，使得我们在防误触上有比较大的进步。最近华为刚发布的mate10以及刚刚在美国发布的，相信在座也有人在用这个手机，如果你再用它的话，它上面每秒120次，一直在运行，是一个高性能的算法，就是我们实验室给它做出来的。　　这个做的结果是什么？是从其他原有产品，误触率在13%，这个体验很不好，我们给它的算法直接降到0.3%，这个体验还是非常好。　　自然交互中，我们还很期待一些很科幻的场景，比如我们在很多科幻片中会有这样的，像手势、姿态的交互和识别。实际上手势识别或者姿态的识别，在人机交互是一个很难的命题，像一些具体的任务上，比如空中打字，也就是我抬手，现在很多人有盲打的能力，实际上你一抬手就在敲你想打的字，你已经有了这个习惯。　　在20多年前，大家就已经设想，未来应该能够实现这样的技术。这个图虽然不是很清楚，右下角是20多年前曾经设想的，在台式机上，不用这个键盘，抬手就可以打字。　　上面这个照片，是我在hollow lens即将发布的时候，在的时候带着它的，今天如果你带了hollow lens，就是VR、AR的技术使得我们眼前可以呈现三维的虚拟对象，那么你跟他进行交互的时候，我那个照片在打的时候，因为hollow lens只支持这样一个动作。那么它的软键盘在我面前，我只能一个一个的点，并且非常不准确。　　看一下我们做的实验结果，对人在空中打字行为所携带的信息量充分挖掘而进行建模。处理充分挖掘是说，我们的主动手、被动手，主动手指、被动手指，以及位置随意的变化、落点和语言模型的结合，可以使得我们实现几十年的理想，科幻的一个结果。实际上用这样的技术，我们还可以实现很多场景下跟踪、交互和自动理解用户的意图。　　交互意图的理解，我们建立了一套，通过数据采集、行为建模以及AI的一些分类算法，最终实现特定交互任务的一套研究方法和体系。我们把它用在手机上，目前希望能有更多的捕捉，因为手机上其实大家不知道，里面有非常多的传感器，并且进去更多所谓的building sensor，还会专门从体系结构上制造一个sensor heart的出现，我们可能能够捕捉更多外在用户的心态，包括卧姿、面部甚至眼神等能力，我们会提供一个手机交互全行为感知的能力，未来大家在使用手机上会有更好的体验。　　从这个角度，所谓智能技术的研究，也就是我们把一些模糊和用户行为习惯识别为具体、准确交互意图的研究，大有可为。即便从我们今天在手机这个问题上来看，我们也仅仅刚刚开始。大家不要以为我们今天的智能手机只是10年前才有，其实30年前就有，这是美国很普及的一本杂志叫《大众科学》，这是它1995年的封面文章，这个图上大家注意到，是1988年左右帕克研制的智能手机，实际上是iPhone原型系统。这cap model当时有各种计算、传感和应用，以及识别的能力。　　这个照片上我们可以看到，它跟我们人类的思想者紧密的结合在一起，共同互相了解和支持，更多的发现世界和获得能力的过程。随着计算超速手机渗入到我们生活更多方面，智能技术的进步，也将为人机共生的美好前景提供支撑的技术。　　很高兴有这样的机会跟大家分享，祝大家新年好！